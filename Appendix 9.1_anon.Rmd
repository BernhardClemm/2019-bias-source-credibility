---
title: |
  | \vspace{1cm}\setstretch{1}Assimilation bias and source credibility in news processing
  | SUPPORTING INFORMATION
date: |
  | `r gsub("^0", "", format(Sys.time(), "%d %B, %Y"))`
linestretch: 1
colorlinks: true
output:
  bookdown::pdf_document2:
    includes:
      in_header: header.tex
    toc: true
    toc_depth: 2
    keep_tex: true
header-includes:
  - \renewcommand{\thetable}{A\arabic{table}}
  - \renewcommand{\figurename}{Table}
  - \renewcommand\thefigure{A\arabic{figure}}
  - \renewcommand{\figurename}{Figure}
fontsize: [12pt, letterpaper]
documentclass: article
geometry: [top=0.85in,left=0.95in,right=0.95in, footskip=0.40in]
bibliography: [References.bib]
csl: apa.csl
link-citations: yes
always_allow_html: yes

---

```{r setup, include = FALSE}

# Knitr options
knitr::opts_chunk$set(cache = TRUE,
                      echo = FALSE,
                      concordance = TRUE,
                      fig.pos = 'H',
                      warning = FALSE,
                      message = FALSE)
# Packages
library(dplyr)
library(tidyr)
library(magrittr)
library(psych)
library(ggplot2)
library(stargazer)
library(ggpubr)
library(margins)
library(modmarg)
library(kableExtra)
library(stringr)
library(rstatix)
library(grf)

# Set locale
Sys.setlocale("LC_ALL", "en_US.UTF-8")

```

```{r data, eval = TRUE, include = FALSE}

# Import

data <- read.csv(file = "data/Data September 2017 Final Raw Anonymous.csv", 
                 stringsAsFactors = FALSE, 
                 encoding = "UTF-8")

# Filter observations

data <- data %>% 
  filter(Finished == "True")

#### Recode & clean

source("code/study_recoding.r") 

```

\clearpage

# Sample and population statistics

The study uses a non-probability quota sample. Tables \@ref(tab:table-quota-sex) through \@ref(tab:table-quota-state) show the sample's distributions on age, gender, education and state of residence in comparison with the population distribution.

```{r quota-function}

population_sample_table <- function(data_set, caption_text, fn_text, 
                                    column_width = NULL, columns_coll = NULL) {
  kable(data_set, 
        caption = caption_text, 
        format = "latex", booktabs = T, longtable = T, escape = F) %>%
    kable_styling(full_width = T,
                  latex_options = c("scale_down", "HOLD_position"),
                  font_size = 10) %>%
    add_header_above(c(" " = 1, "Population" = 2,
                       "Sample" = 2)) %>%
    footnote(alphabet = fn_text, threeparttable = T) %>%
    column_spec(1, width = column_width)
    # collapse_rows(columns = columns_coll, valign = "middle", latex_hline = "none")
}

```

```{r table-quota-sex, paged.print=FALSE}

population_sex <- read.csv("data/sex_quotas.csv") %>%
  mutate(population_percent = population_percent * 100)

data_sex <- data.frame(
  sex = names(prop.table(table(data$sex))),
  data_abs = as.numeric(table(data$sex)),
  data_rel = as.numeric(prop.table(table(data$sex)) * 100)
) %>%
  mutate(sex = case_when(
    sex == 0 ~ "male",
    sex == 1 ~ "female"
  ))

population_data_sex <- left_join(
  population_sex, data_sex, by = "sex") %>%
  mutate_if(is.numeric, round, 2)

colnames(population_data_sex) <- c(
  "Sex", paste0("Abs.", footnote_marker_alphabet(1)),
  "Percent", "Abs.", "Percent"
)

population_sample_table(population_data_sex,
  "Sex distribution of population and samples",
  "Population statistics refer to the adult population. 2011 census data extrapolated to 2017 by https://www-genesis.destatis.de/",
  column_width = NULL
)

```

```{r table-quota-age, paged.print=FALSE}

population_age <- read.csv("data/age_quotas.csv") %>% 
  mutate(population_percent = population_percent*100) 

data_age <- data.frame(
  age = names(prop.table(table(data$age_group_census))),
  data_abs = as.numeric(table(data$age_group_census)),
  data_rel = as.numeric(prop.table(table(data$age_group_census))*100))
  
population_data_age <- left_join(
  population_age, data_age, by = "age") %>% 
  mutate_if(is.numeric, round, 2)

colnames(population_data_age) <- c(
  "Age", paste0("Abs.", footnote_marker_alphabet(1)),
  "Percent", "Abs.", "Percent"
)

population_sample_table(
  population_data_age, 
  "Age distribution of population and samples", 
  "Population statistics refer to the adult population. 2011 census data extrapolated to 2017 by https://www-genesis.destatis.de/", 
  column_width = NULL
)

```

```{r table-quota-education, paged.print=FALSE}

population_education <- read.csv("data/education_quotas.csv") %>% 
  mutate(population_percent = population_percent*100) %>%
  rename("education_en" = education_6)

data_education <- data.frame(
  education_en = names(prop.table(table(data$education_en))),
  data_abs = as.numeric(table(data$education_en)),
  data_rel = as.numeric(prop.table(table(data$education_en))*100))

population_data_education <- left_join(
  population_education, data_education, by = "education_en") %>% 
  mutate_if(is.numeric, round, 2) 

population_data_education[6, "population_absolute"] <- 
  population_data_education[5, "population_absolute"]
population_data_education[6, "population_percent"] <- 
  population_data_education[5, "population_percent"]

colnames(population_data_education) <- c(
  "Education", paste0("Abs.", footnote_marker_alphabet(1)),
  "Percent", "Abs.", "Percent"
)

population_sample_table(
  population_data_education, 
  "Education distribution of population and samples", 
  "Population statistics refer to the adult population. 2011 census data extrapolated to 2017 by https://www-genesis.destatis.de/", 
  column_width = "5.5cm", columns_coll = c(2:3))

```

```{r table-quota-state, paged.print=FALSE}

population_states <- read.csv("data/federal_state_quotas.csv") %>% 
  rename(federal_state = state) %>% 
  mutate(federal_state = case_when(
    federal_state == "Baden-Wuerttemberg" ~ "Baden-Württemberg",
    federal_state == "Thueringen" ~ "Thüringen",
    TRUE ~ as.character(federal_state))) %>% 
  mutate(population_percent = population_percent*100) 

data_states <- data.frame(
  federal_state = names(prop.table(table(data$federal_state))),
  data_abs = as.numeric(table(data$federal_state)),
  data_rel = as.numeric(prop.table(table(data$federal_state))*100))

population_data_states <- left_join(
  population_states, data_states, by = "federal_state") %>% 
  mutate_if(is.numeric, round, 2)

colnames(population_data_states) <- c(
  "Federal state", paste0("Abs.", footnote_marker_alphabet(1)),
  "Percent", "Abs.", "Percent"
)

population_sample_table(
  population_data_states, 
  "Geographic distribution of population and samples", 
  "Population statistics refer to the adult population. 2011 census data extrapolated to 2017 by https://www-genesis.destatis.de/", 
  column_width = "4cm", columns_coll = c(2:3))

```

# Treatment balance

Tables \@ref(tab:table-balance-content) and \@ref(tab:table-balance-source) show balance statistics across the two treatment dimensions analysed, i.e. content and source. Variables include basic sociodemographics and those relevant for hypotheses. As treatments were re-assigned for each topic, four differences are displayed for each variable for Study 1. Note that for one attitude item, content treatment groups are imbalanced (bold p-value). Since this covariate is included in the analysis anyway, the imbalance can be ignored [cf. @MutzPemantle2015, p. 201].

```{r balance-function}

balance_df <- function(treatment, attitude, topic) {
  
  balance <- data %>%
    mutate(treatment = !!as.name(treatment),
           attitude = !!as.name(attitude)) %>%
    select(
      treatment, sex, age,
      education_high, federal_state_west,
      attitude
    ) %>%
    mutate(treatment = case_when(
      treatment == 0 ~ "zero",
      treatment == 1 ~ "one",
      treatment == 2 ~ "two",
      treatment == 3 ~ "three"
    )) %>%
    pivot_longer(
      cols = c(
        sex, age, education_high,
        federal_state_west, attitude
      ),
      names_to = "variable"
    ) %>%
    group_by(treatment, variable) %>%
    summarise(value = list(value)) %>%
    pivot_wider(
      names_from = "treatment",
      values_from = "value"
    ) 
  
  if (length(table(data[, treatment])) == 2) {
    balance <- balance %>% 
      group_by(variable) %>%
      mutate(
        p_value = t.test(unlist(zero), unlist(one))$p.value,
        zero = mean(unlist(zero), na.rm = TRUE),
        one = mean(unlist(one), na.rm = TRUE),
        topic = topic,
        across(where(is.numeric), round, 2))
  } else {
    aov_age <- aov(age ~ treatment, data = crop.data)
  }
    
  return(balance)
}


```

```{r table-balance-content, results="asis"}

balance_topic1_content <- balance_df(
  treatment = "topic1_content",
  attitude = "topic1_attitudes_average",
  topic = "Topic 1"
)

balance_topic2_content <- balance_df(
  treatment = "topic2_content",
  attitude = "topic2_attitudes_average",
  topic = "Topic 2"
)

balance_topic3_content <- balance_df(
  treatment = "topic3_content",
  attitude = "topic3_attitudes_average",
  topic = "Topic 3"
)

balance_topic4_content <- balance_df(
  treatment = "topic4_content",
  attitude = "topic4_attitudes_average",
  topic = "Topic 4"
)

balance_content <- rbind(
  balance_topic1_content,
  balance_topic2_content,
  balance_topic3_content,
  balance_topic4_content) %>%
  arrange(variable) %>%
  select(
    variable, topic, one, zero, p_value) %>%
  rename("Topic" = topic,
         "Variable" = variable,
         "Left-wing" = zero,
         "Right-wing" = one) %>%
  mutate(
    Topic = case_when(
      Topic == "Topic 1" ~ "Welfare State",
      Topic == "Topic 2" ~ "Domestic Security",
      Topic == "Topic 3" ~ "Immigration",
      Topic == "Topic 4" ~ "European Integration"),
    Variable = case_when(
      Variable == "age" ~ "Age (mean)",
      Variable == "attitude" ~ "Attitude index (mean)",
      Variable == "education_high" ~ "Education (prop. high)",
      Variable == "federal_state_west" ~ "Residence (prop. West)",
      Variable == "sex" ~ "Sex (prop. female")) %>%
  mutate(p_value = cell_spec(p_value, "latex", bold = ifelse(p_value < 0.05, T, F)))

colnames(balance_content)[5] <- paste0("Significance", footnote_marker_alphabet(1))

kable(balance_content, 
      caption = "Balance statistics for content treatment", 
      format = "latex", booktabs = T, linesep = "", longtable = T, escape = F) %>%
  kable_styling(full_width = T,
                latex_options = c("scale_down", "HOLD_position"),
                font_size = 10) %>%
  collapse_rows(columns = 1, valign = "middle", latex_hline = "none") %>%
  column_spec(1, width = "3.5cm") %>%
  column_spec(2, width = "3.5cm") %>%
  column_spec(3:5, width = "1.8cm") %>%
  footnote(alphabet = c("p-value of t-test for proportions and means. Differences significant at 5%-level in bold."), threeparttable = T)

``` 

```{r table-balance-source, results="asis"}

balance_topic1_source <- balance_df(
  treatment = "topic1_source",
  attitude = "topic1_attitudes_average",
  topic = "Topic 1"
)

balance_topic2_source <- balance_df(
  treatment = "topic2_source",
  attitude = "topic2_attitudes_average",
  topic = "Topic 2"
)

balance_topic3_source <- balance_df(
  treatment = "topic3_source",
  attitude = "topic3_attitudes_average",
  topic = "Topic 3"
)

balance_topic4_source <- balance_df(
  treatment = "topic4_source",
  attitude = "topic4_attitudes_average",
  topic = "Topic 4"
)

balance_source <- rbind(
  balance_topic1_source,
  balance_topic2_source,
  balance_topic3_source,
  balance_topic4_source) %>%
  arrange(variable) %>%
  select(
    variable, topic, one, zero, p_value) %>%
  rename("Topic" = topic,
         "Variable" = variable,
         "Left-wing" = zero,
         "Right-wing" = one) %>%
  mutate(
    Topic = case_when(
      Topic == "Topic 1" ~ "Welfare State",
      Topic == "Topic 2" ~ "Domestic Security",
      Topic == "Topic 3" ~ "Immigration",
      Topic == "Topic 4" ~ "European Integration"),
    Variable = case_when(
      Variable == "age" ~ "Age (mean)",
      Variable == "attitude" ~ "Attitude index (mean)",
      Variable == "education_high" ~ "Education (prop. high)",
      Variable == "federal_state_west" ~ "Residence (prop. West)",
      Variable == "sex" ~ "Sex (prop. female")) %>%
  mutate(p_value = cell_spec(p_value, "latex", bold = ifelse(p_value < 0.05, T, F)))

colnames(balance_source)[5] <- paste0("Significance", footnote_marker_alphabet(1))

kable(balance_source, 
      caption = "Balance statistics for source treatment", 
      format = "latex", booktabs = T, linesep = "", longtable = T, escape = F) %>%
  kable_styling(full_width = T,
                latex_options = c("scale_down", "HOLD_position"),
                font_size = 10) %>%
  collapse_rows(columns = 1, valign = "middle", latex_hline = "none") %>%
  column_spec(1, width = "3.5cm") %>%
  column_spec(2, width = "3.5cm") %>%
  column_spec(3:5, width = "1.8cm") %>%
  footnote(alphabet = c("p-value of t-test for proportions and means. Differences significant at 5%-level in bold."), threeparttable = T)

``` 

```{r table-balance-interaction, results="asis", eval = F}

balance_topic1_interaction <- balance_df(
  treatment = "topic1_interaction",
  attitude = "topic1_attitudes_average",
  topic = "Topic 1"
)

balance_topic2_interaction <- balance_df(
  treatment = "topic2_interaction",
  attitude = "topic2_attitudes_average",
  topic = "Topic 2"
)

balance_topic3_interaction <- balance_df(
  treatment = "topic3_interaction",
  attitude = "topic3_attitudes_average",
  topic = "Topic 3"
)

balance_topic4_interaction <- balance_df(
  treatment = "topic4_interaction",
  attitude = "topic4_attitudes_average",
  topic = "Topic 4"
)

balance_interaction <- rbind(
  balance_topic1_interaction,
  balance_topic2_interaction,
  balance_topic3_interaction,
  balance_topic4_interaction) %>%
  arrange(variable) %>%
  select(
    variable, topic, one, zero) %>%
  rename("Topic" = topic,
         "Variable" = variable,
         "Left-wing" = zero,
         "Right-wing" = one) %>%
  mutate(
    Topic = case_when(
      Topic == "Topic 1" ~ "Welfare State",
      Topic == "Topic 2" ~ "Domestic Security",
      Topic == "Topic 3" ~ "Immigration",
      Topic == "Topic 4" ~ "European Integration"),
    Variable = case_when(
      Variable == "age" ~ "Age",
      Variable == "attitude" ~ "Attitude index",
      Variable == "education_high" ~ "Education (proportion High School +)",
      Variable == "federal_state_west" ~ "Residence (proportion West)",
      Variable == "sex" ~ "Sex"))
  
kable(balance_interaction, 
      caption = "Balance statistics for content*source treatment", 
      format = "latex", booktabs = T, linesep = "", longtable = T, escape = F) %>%
  kable_styling(full_width = T,
                latex_options = c("scale_down", "HOLD_position"),
                font_size = 10) %>%
  collapse_rows(columns = 1, valign = "middle", latex_hline = "none") %>%
  footnote(alphabet = c("p-value of t-test for proportions and means. Differences significant at 5%-level in bold."), threeparttable = T)

``` 

# Attitude measurement

```{r attitude-hist-function}

attitude_hist <- function(dt, attitude, ymax, y_lab, x_lab) {
  ggplot(dt, aes(x = attitude)) + 
    geom_histogram(colour = "white", fill="grey", bins = 11) + 
    geom_vline(aes(xintercept = mean(attitude, na.rm = TRUE)),
               color="black", linetype="dashed", size=0.5) +
    theme_light() +
    labs(y = y_lab, x = x_lab) +
    ylim(0, ymax) + 
    scale_x_continuous(breaks = c(-5, 0, 5))
} 

```

For each of the four topics, subjects were asked to indicate their agreement with four statements on an 11-point scale. Question wordings are provided below, as well as the distributions of single items and composite indices (coded so that left end of the scale always represents are politically left position). 

## Welfare state {-}

* "The current wealth and income distribution in Germany is unjust." (reverse coded)
* "Someone working hard nowadays can improve their life situation without much difficulty."
* "The state should do more for the support of the unemployed even if that means raising taxes or incurring public debt." (reverse coded)
* "Wealth tax should be re-introduced." (reverse coded)

```{r study1-topic1-attitudes, fig.cap="Distributions of welfare state attitudes", fig.height=3.8, fig.width = 5.6, out.extra = '', fig.pos= "ht", fig.align = "center"}

topic1_attitude1_hist <- attitude_hist(data, data$topic1_attitude1, 
                                       150, "Frequency", 
                                       "Income/wealth distribution")

topic1_attitude2_hist <- attitude_hist(data, data$topic1_attitude2, 
                                       150, "", "Effect of working hard")
  
topic1_attitude3_hist <- attitude_hist(data, data$topic1_attitude3, 
                                       150, "Frequency", "Support for unemployed")

topic1_attitude4_hist <- attitude_hist(data, data$topic1_attitude4, 
                                       150, "", "Wealth tax")

topic1_attitudes_average_hist <- attitude_hist(data, data$topic1_attitudes_average, 
                                               150, "Frequency", 
                                               "Welfare state attitude index")

topic1_attitudes_single <- ggarrange(topic1_attitude1_hist,
                           topic1_attitude2_hist,
                           topic1_attitude3_hist,
                           topic1_attitude4_hist,
                           ncol = 2, nrow = 2)

ggarrange(topic1_attitudes_average_hist, topic1_attitudes_single,
                              common.legend = TRUE, 
                              legend = "bottom", 
                              ncol = 2, 
                              widths = c(2,3))
```

## Domestic security {-}

* "Courts treat violent criminals too leniently." 
* "Overall, our country is well protected against terrorism."
* "The state should take a tougher stance on terrorist suspects."
* "The state should implement more CCTV in the public space."

```{r study1-topic2-attitudes, fig.cap="Distributions of domestic security attitudes", fig.height=3.8, fig.width = 5.6, out.extra = '', fig.pos= "ht", fig.align = "center"}

topic2_attitude1_hist <- attitude_hist(data, data$topic2_attitude1, 
                                       150, "Frequency", 
                                       "Treatment of criminals")

topic2_attitude2_hist <- attitude_hist(data, data$topic2_attitude2, 
                                       150, "", "Terrorism protection")
  
topic2_attitude3_hist <- attitude_hist(data, data$topic2_attitude3, 
                                       150, "Frequency", "Stance on terrorist suspects")

topic2_attitude4_hist <- attitude_hist(data, data$topic2_attitude4, 
                                       150, "", "Public CCTV")

topic2_attitudes_average_hist <- attitude_hist(data, data$topic2_attitudes_average, 
                                               150, "Frequency", 
                                               "Domestic security attitude index")

topic2_attitudes_single <- ggarrange(topic2_attitude1_hist,
                           topic2_attitude2_hist,
                           topic2_attitude3_hist,
                           topic2_attitude4_hist,
                           ncol = 2, nrow = 2)

ggarrange(topic2_attitudes_average_hist, topic2_attitudes_single,
                              common.legend = TRUE, 
                              legend = "bottom", 
                              ncol = 2, 
                              widths = c(2,3))


```

## Migration {-}

* "I appreciate that Germany has taken in many refugees." (reverse coded)
* "There should be an upper limit for number of refugees taken in."
* "The German state is more concerned about refugees than Germans in need."
* "The living standard of Germans will decrease because of the reception of refugees."

```{r study1-topic3-attitudes, fig.cap="Distributions of migration attitudes", fig.height=3.8, fig.width = 5.6, out.extra = '', fig.pos= "ht", fig.align = "center"}

topic3_attitude1_hist <- attitude_hist(data, data$topic3_attitude1, 
                                       150, "Frequency", 
                                       "Intake of refugees")

topic3_attitude2_hist <- attitude_hist(data, data$topic3_attitude2, 
                                       150, "", "Limit on refugees")
  
topic3_attitude3_hist <- attitude_hist(data, data$topic3_attitude3, 
                                       150, "Frequency", "Germans in need")

topic3_attitude4_hist <- attitude_hist(data, data$topic3_attitude4, 
                                       150, "", "Living standards")

topic3_attitudes_average_hist <- attitude_hist(data, data$topic3_attitudes_average, 
                                               150, "Frequency", 
                                               "Domestic security attitude index")

topic3_attitudes_single <- ggarrange(topic3_attitude1_hist,
                           topic3_attitude2_hist,
                           topic3_attitude3_hist,
                           topic3_attitude4_hist,
                           ncol = 2, nrow = 2)

ggarrange(topic3_attitudes_average_hist, topic3_attitudes_single,
                              common.legend = TRUE, 
                              legend = "bottom", 
                              ncol = 2, 
                              widths = c(2,3))

```

## European integration{-}

* "Germany should have a referendum on its EU membership."
* "The EU interferes too much with Europeans' lives."
* "Germany should pay less into the EU budget."
* "Countries with financial problems should be excluded from the Euro zone."

```{r study1-topic4-attitudes, fig.cap="Distributions of European integration attitudes", fig.height=3.8, fig.width = 5.6, out.extra = '', fig.pos= "ht", fig.align = "center"}

topic4_attitude1_hist <- attitude_hist(data, data$topic4_attitude1, 
                                       150, "Frequency", 
                                       "EU referendum")

topic4_attitude2_hist <- attitude_hist(data, data$topic4_attitude2, 
                                       150, "", "EU interference")
  
topic4_attitude3_hist <- attitude_hist(data, data$topic4_attitude3, 
                                       150, "Frequency", "EU budget")

topic4_attitude4_hist <- attitude_hist(data, data$topic4_attitude4, 
                                       150, "", "Euro zone")

topic4_attitudes_average_hist <- attitude_hist(data, data$topic4_attitudes_average, 
                                               150, "Frequency", 
                                               "Domestic security attitude index")

topic4_attitudes_single <- ggarrange(topic4_attitude1_hist,
                           topic4_attitude2_hist,
                           topic4_attitude3_hist,
                           topic4_attitude4_hist,
                           ncol = 2, nrow = 2)

ggarrange(topic4_attitudes_average_hist, topic4_attitudes_single,
                              common.legend = TRUE, 
                              legend = "bottom", 
                              ncol = 2, 
                              widths = c(2,3))

```

\clearpage

# Stimuli and content manipulations

For each topic, the main stimulus was a screenshot of a Facebook post containing a news report. The post was built like a typical news post and included a headline, a photo, a teaser, the name and logo of the source as well as its URL. Contents were manipulated so that the two content treatments contained opposing factual claims. For the topics of immigration and European integration, a couple of paragraphs of the report were shown in addition to the Facebook post, introduced by the words: "For this story, we will show you a few paragraphs of the linked text (Source: [source])". Figure \@ref(fig:study1-screenshots) illustrates the two treatment dimensions. Wording of news reports translated from German below. Square brackets indicate differences between treatments. The left-wing content ttreatment always comes first within a square bracket.

## Welfare state

*Headline*: *Hartz IV benefit cuts: Sanctions [push unemployed into ill-paid jobs /speed up entry into regular employment]

*Teaser*: Benefit cuts for those who violate Hartz IV requirements [fall short of desired effects / are effective]: Our data [show that sanctioned move into ill-paid jobs. The risk of becoming a working poor increases / suggest that sanctioned unemployed move more often and more quickly into regular employment]. 

## Domestic security

*Headline*: Europe-wide comparison: [Arrest of terrorist suspects does not decrease risk of terrorism / Fewer terrorist attacks in countries with strict arrest of terrorist suspects] 

*Teaser*: Is the pre-emptive arrest of terrorist suspects reasonable? European countries with stricter measures have [not experienced / experienced] less terrorist attacks in the last ten years, as a study shows.

## Immigration

*Headline*: [Craft traineeships: Completion rates in craft as high for refugees as for natives / Craft traineeships: Nine out of ten refugees cancel their traineeship]

*Teaser*: Refugees [complete their craft traineeships by now as often as other trainees / discontinue their craft traineeships more often than average], as numbers by the Chamber of Crafts show.* 

*Text*: Refugees [complete / discontinue] their traineeships in German handicraft businesses [as often as native trainees / more often than average]. [About three quarter / Almost 90 percent] of trainees who had fled from Syria, Afghanistan and Iraq and had started a traineeship since the beginning of 2013 [have by now completed or are still in training / have dropped out without finishing], as a Germany-wide investigation by [source] revealed. [Their completion rate (74.8 percent) corresponds roughly to that of all other trainees (73.5 percent) / For all other trainees, the dropout rate is substantially lower at around 25 percent]. 

For the investigation, data from the Chambers of Craft of all German states were analysed. The Chambers have initiated various programmes for the integration of refugees into the labour market and recorded the numbers of allocated and successfully trained refugees. The dropout rates are not equally high for all states and fluctuate between [85 / 60] percent (Saarland) and [65 / 95] percent (Lower Saxony). On average, the rate is [74.8 / 89.5] percent. [Anecdotal numbers from earlier periods had painted a much worse picture / ]. 

When asked for the reasons [for the apparent rise of completion rates, several representatives of businesses and Chambers refer to more realistic expectations of refugees / several representatives of businesses and Chambers refer to unrealistic expectations on the refugees' part]. '[In the beginning, many have the idea of earning lots of money in Germany quickly and send it back home / Many have the idea of earning lots of money in Germany quickly and send it back home]', said Lothar Semper from the Chamber Munich and Upper Bavaria. [Now they understand / It is necessary to communicate to them], he said, that in the long run [opting for a traineeship is a better decision / it is worth opting for a traineeship and earn less at the start]. [The majority accepts the comparably low wage during the traineeship and show a particularly high motivation / Given the comparably low wage during the traineeship much persuasion is necessary to bring young people to start a traineeship in the first place].

## European integration

*Headline*: EU programme to reduce regulations [shows effects / unsuccessful, but costly]

*Teaser*: Since two years ago, a programme of the EU Commission is meant to repeal unnecessary legislation. [With success: Over 60 pieces of regulation have been abolished, which financially relieved small entreprises in particular / This has not happened: Not a single regulation has been abolished, but the programme has created additional costs]

*Paragraphs*: A EU programme for more efficiency in legislation has [led to less regulation and financial relief for citizens and businesses / has not led to less regulation, but higher costs]. This is the result of an investigation by [source]. In the years of 2015 and 2016, the working group 'Refit' made 119 proposals to the Commission how EU regulations could be repealed or modified. [Of the 53 proposed modifications and the 66 pieces of regulation to be abolished, most were already follwed through. Only eight pieces of regulation remain to be repealed. / Of these, only the 53 proposed modifications were implemented. Those 66 pieces of regulation that were supposed to be abolished exist until today]. 

[According to the Commissions estimations, the 'Refit' changes could mean yearly savings for citizens and entreprises of 1.5 billion Euros alone. In comparison, the programme 'Refit' has only produced costs of 5 million Euros. Small and medium business owners interviewed by [source] have confirmed that many of the repealed rules could mean financial relief. / The working group, however, produced additional costs for staff and technical infrastructure of 25 million Euros. Via the EU budget, Germany contributed 3.8 million.] 

The programme 'Refit' was born in 2015 to make EU law "simpler and less costly". Regulation can be regularly examined and changed or repealed as needed. This is meant to cut red tape and reduce costs for small entreprises in particular. Through an online platform, citizens, business and member states can make proposals on modifications and repeals. [ / Why the Commission has not repealed a single legislation during the first two years of Refit's existence although there is a choice of over 60 pieces of regulation is uncelar. The Commission declined to comment questions on the investigation from [source].]

## True control story

*Headline*: State parliament election in North Rhine-Westphalia: The Free Democratic Party gains 28 seats
*Teaser*: The official final result is confirmed: Free Democratic Party gets 28 out of 199 seats in North Rhine-Westphalia parliamentary elections.

\begin{figure}[htb]
\caption{Example of screenshots used in Study 1}
  \begin{subfigure}{8cm}
    \centering\includegraphics[width=8cm]{figures/Study 1 TS Left}
    \caption{Real source, left-wing content}
  \end{subfigure}
  \begin{subfigure}{8cm}
    \centering\includegraphics[width=8cm]{figures/Study 1 TS Right}
    \caption{Real source, right-wing content}
  \end{subfigure}

  \begin{subfigure}{8cm}
    \centering\includegraphics[width=8cm]{figures/Study 1 NN Left}
    \caption{Fake source, right-wing content}
  \end{subfigure}
  \begin{subfigure}{8cm}
    \centering\includegraphics[width=8cm]{figures/Study 1 NN Right}
    \caption{Fake source, left-wing content}
  \end{subfigure}
\label{fig:study1-screenshots}
\end{figure}

\clearpage

# Source pre-testing

A list of 30 sources, including the real source later used in the experiment (Tagesschau) was pre-tested before Study 1. Figure \@ref(fig:fig-study1-pretest-know) shows the percentages of people knowing a source, Figure \@ref(fig:fig-study1-pretest-trust) average trust scores per source.

```{r study1-pretest-know, fig.cap="Source knowledge pre-test Study 1 \\label{fig:fig-study1-pretest-know}", out.extra = '', fig.pos= "h", fig.align = "center", fig.width = 9, fig.height=3.5}

study1_pretest <- read.csv(file = "data/Data Pretest August 2017.csv", 
                           stringsAsFactors = FALSE, 
                           encoding = "UTF-8")
study1_pretest <- study1_pretest[-c(1:3),]

mainstream <-  c("Spiegel", "Tagesschau", "ZDF", "Welt", "SZ", 
         "Zeit", "FAZ", "Bild", "Focus", "Express", "TAZ",
         "Huffington", "T-Online", "web.de", "DPA", "Reuters", "NTV")
hyperpartisan <- c("Junge_Freiheit", "Achse", "Tichys", "PI",
                   "Neues", "Jungle_World", "Junge_Welt")
fakenews <- c("24aktuelles", "Abendblatt", 
              "Anonymous", "Newsblitz", "Internetzzeitung", "Chintzyherald")

study1_pretest %<>% 
  rename("Spiegel_trust" = Q1_1,
         "Tagesschau_trust" = Q1_2,
         "ZDF_Heute_trust" = Q1_3,
         "Welt_trust" = Q1_4,   
         "SZ_trust" = Q1_5,
         "Zeit_trust" = Q1_6,   
         "FAZ_trust" = Q1_7,   
         "Bild_trust" = Q1_8,   
         "Focus_trust" = Q1_9,   
          "Express_trust" = Q1_10,   
          "Huffington_Post_trust" = Q1_11,   
          "T-Online_trust" = Q1_12,   
          "web.de_trust" = Q1_13,   
          "DPA_trust" = Q1_14,   
          "Reuters_trust" = Q1_15,   
          "Junge_Freiheit_trust" = Q1_16,   
          "Achse_des_Guten_trust" = Q1_17,   
          "Tichys_Einblick_trust" = Q1_18,   
          "PI_News_trust" = Q1_19,   
          "TAZ_trust" = Q1_20,   
          "Neues_Deutschland_trust" = Q1_21,   
          "Jungle_World_trust" = Q1_22,   
          "Junge_Welt_trust" = Q1_23,   
          "24aktuelles_trust" = Q1_24,   
          "Koelner_Abendblatt_trust" = Q1_25,   
          "Anonymous_Russia_trust"= Q1_26,   
          "Newsblitz_trust" = Q1_27,   
          "Internetzzeitung_trust" = Q1_28,   
          "Chintzyherald_trust" = Q1_29,   
          "NTV_trust" = Q1_30) %>%
  rename("Spiegel_know" = Q14.1_1,
         "Tagesschau_know" = Q14.1_2,
         "ZDF_Heute_know" = Q14.1_3,
         "Welt_know" = Q14.1_4,   
         "SZ_know" = Q14.1_5,
         "Zeit_know" = Q14.1_6,   
         "FAZ_know" = Q14.1_7,   
          "Bild_know" = Q14.1_8,   
          "Focus_know" = Q14.1_9,   
          "Express_know" = Q14.1_10,   
          "Huffington_Post_know" = Q14.1_11,   
          "T-Online_know" = Q14.1_12,   
          "web.de_know" = Q14.1_13,   
          "DPA_know" = Q14.1_14,   
          "Reuters_know" = Q14.1_15,   
          "Junge_Freiheit_know" = Q14.1_16,   
          "Achse_des_Guten_know" = Q14.1_17,   
          "Tichys_Einblick_know" = Q14.1_18,   
          "PI_News_know" = Q14.1_19,   
          "TAZ_know" = Q14.1_20,   
          "Neues_Deutschland_know" = Q14.1_21,   
          "Jungle_World_know" = Q14.1_22,   
          "Junge_Welt_know" = Q14.1_23,   
          "24aktuelles_know" = Q14.1_24,   
          "Koelner_Abendblatt_know" = Q14.1_25,   
          "Anonymous_Russia_know"= Q14.1_26,   
          "Newsblitz_know" = Q14.1_27,   
          "Internetzzeitung_know" = Q14.1_28,   
          "Chintzyherald_know" = Q14.1_29,   
          "NTV_know" = Q14.1_30) 

study1_pretest_know <- study1_pretest %>% 
  select(ends_with("know")) %>%
  pivot_longer(ends_with("know"), 
               names_to = "source", values_to = "value") %>% 
  mutate(value = ifelse(value == "Kenne ich", 1, 0)) %>%
  group_by(source) %>%
  get_summary_stats(value) %>%
  mutate(conf_high = mean + qt(0.975, n - 1) * se,
         conf_low = mean - qt(0.975, n - 1) * se) %>%  
  mutate(type = case_when(grepl(paste(mainstream, collapse="|"), 
                                .$source) == TRUE ~ "Mainstream",
                          grepl(paste(hyperpartisan, collapse="|"), 
                                .$source) == TRUE ~ "Hyperpartisan",
                          grepl(paste(fakenews, collapse="|"), 
                                .$source) == TRUE ~ "Fake news")) %>%
  arrange(desc(mean))

ggplot(study1_pretest_know, aes(x = reorder(source, -mean), 
                                 y = mean,
                                 color = as.factor(type))) +
  geom_point(position = position_dodge(0), size = 1) +
  geom_errorbar(aes(ymin = conf_low, ymax = conf_high), width=0.7,
                   position = position_dodge(0.4), size = 0.8) +
  scale_color_manual(name = "Type of news source",
                     values = c("grey70", "grey45", "grey10")) + 
  labs(x = "", y = "Proportion") + 
  scale_x_discrete(labels = gsub("_"," ", gsub("_know", "", study1_pretest_know$source))) +
  scale_y_continuous(breaks = c(0, 0.5, 1),
                     limits = c(0, 1)) +
  theme_light()+
  theme(axis.text.x = element_text(angle = 35, hjust = 1, vjust = 1, 
                                   margin = margin(0.2,0,0.3,0,"cm")),
        panel.grid.minor.x = element_blank(),
        panel.grid.major.x = element_blank())


```

```{r study1-pretest-trust, fig.cap="Source trust pre-test Study 1 \\label{fig:fig-study1-pretest-trust}", out.extra = '', fig.pos= "h", fig.align = "center", fig.width = 9, fig.height=3.5}

study1_pretest_trust <- study1_pretest %>% 
  select(ends_with("trust")) %>%
  pivot_longer(ends_with("trust"), 
               names_to = "source", values_to = "value") %>% 
  group_by(source) %>%
  get_summary_stats(value) %>%
  mutate(conf_high = mean + qt(0.975, n - 1) * se,
         conf_low = mean - qt(0.975, n - 1) * se) %>%
  mutate(type = case_when(grepl(paste(mainstream, collapse="|"), 
                                .$source) == TRUE ~ "Mainstream",
                          grepl(paste(hyperpartisan, collapse="|"), 
                                .$source) == TRUE ~ "Hyperpartisan",
                          grepl(paste(fakenews, collapse="|"), 
                                .$source) == TRUE ~ "Fake news")) %>%
  arrange(desc(mean))

ggplot(study1_pretest_trust, aes(x = reorder(source, -mean), 
                                 y = mean,
                                 color = as.factor(type))) +
  geom_point(position = position_dodge(0), size = 1) +
  geom_errorbar(aes(ymin = conf_low, ymax = conf_high), width=0.7,
                   position = position_dodge(0.4), size = 0.8) +
  scale_color_manual(name = "Type of news source",
                     values = c("grey70", "grey45", "grey10")) + 
  labs(x = "", y = "Average") + 
  scale_x_discrete(labels = gsub("_"," ", gsub("_trust", "", study1_pretest_trust$source))) +
  scale_y_continuous(breaks = c(0, 2, 4, 6, 8, 10),
                     limits = c(0, 10)) +
  theme_light()+
  theme(axis.text.x = element_text(angle = 35, hjust = 1, vjust = 1, 
                                   margin = margin(0.2,0,0.3,0,"cm")),
        panel.grid.minor.x = element_blank(),
        panel.grid.major.x = element_blank())

```

# Power analysis

Below, I present a simulation to estimate the statistical power to detect true effects with the target sample size of 400. Similar to the logic proposed by @Blairetal2019, I start by defining "true" treatment means that reflect my expectations, and a normally distributed individual error and a normally distributed attitude variable. Since two of the hypotheses suggest an interaction with this attitude dimension, I define potential outcomes as a function of treatment and individual attitude position. In the simulation, treatments are then assigned randomly 250 times, and each time the regressions pertinent to hypotheses H1, H2, H3 are run. 

The target sample size is sufficiently large to detect small effects predicted by hypotheses H1 and H2: In over 95 percent of simulations, the respective regression terms are statistically significant. The power to detect the effect predicted by H3 is much smaller. However, for moderate effect sizes, the regression term testing H3 turns out statistically significant in more than 90 percent of simulations. 

```{r power-analysis, echo = TRUE, results = "asis"}

# Data-generating model

n_sample <- 400

data_sim <- data.frame(attitude = rnorm(n_sample, 0, 1.5),
                       error = rnorm(n_sample, 0, 0.55)) # assuming prognostic covariates

## Small effect sizes

### Treatment means (Content treatment (A): 0 = left-wing; 1 = right-wing; 
### Source treatment (B): 0 = low-credibility, 1 = high-credibility)

belief_A_0_B_0_mean <- -0.125
belief_A_0_B_1_mean <- 0.125
belief_A_1_B_0_mean <- -0.125
belief_A_1_B_1_mean <- 0.125

### Potential outcomes reflecting interaction hypotheses

data_sim_small <- data_sim %>%
  mutate(belief_A_0_B_0 = belief_A_0_B_0_mean - 0.10*attitude + error,
         belief_A_0_B_1 = belief_A_0_B_1_mean - 0.05*attitude + error,
         belief_A_1_B_0 = belief_A_1_B_0_mean + 0.10*attitude + error,
         belief_A_1_B_1 = belief_A_1_B_1_mean + 0.05*attitude + error)

## Moderate effect sizes

### Treatment means (Content treatment (A): 0 = left-wing; 1 = right-wing; 
### Source treatment (B): 0 = low-credibility, 1 = high-credibility)

belief_A_0_B_0_mean <- -0.25
belief_A_0_B_1_mean <- 0.25
belief_A_1_B_0_mean <- -0.25
belief_A_1_B_1_mean <- 0.25

### Potential outcomes reflecting interaction hypotheses

data_sim_mod <- data_sim %>%
  mutate(belief_A_0_B_0 = belief_A_0_B_0_mean - 0.20*attitude + error,
         belief_A_0_B_1 = belief_A_0_B_1_mean - 0.05*attitude + error,
         belief_A_1_B_0 = belief_A_1_B_0_mean + 0.20*attitude + error,
         belief_A_1_B_1 = belief_A_1_B_1_mean + 0.05*attitude + error)

# Simulations

n_simulations <- 250

## Small effect sizes

simulation_small <- data.frame(index = 1:n_simulations,
                         source_coeff = NA, source_se = NA, source_p = NA,
                         content_att_coeff = NA, content_att_se = NA, content_att_p = NA,
                         content_source_att_coeff = NA, content_source_att_se = NA,
                         content_source_att_p = NA)

for (i in 1:n_simulations) {
  
  # Simulate random treatment assignment
  data_sim_assigned <- data_sim_small %>%
    mutate(content = sample(0:1, n_sample, replace = TRUE),
           source = sample(0:1, n_sample, replace = TRUE)) %>%
    mutate(belief = case_when(content == 0 & source == 0 ~ belief_A_0_B_0,
                              content == 0 & source == 1 ~ belief_A_0_B_1,
                              content == 1 & source == 0 ~ belief_A_1_B_0,
                              content == 1 & source == 1 ~ belief_A_1_B_1))
  
  # Regressions for three different hypotheses
  reg_h1 <- summary(glm(belief ~ source, 
                        data = data_sim_assigned))$coefficients
  simulation_small[i, "source_coeff"] <- reg_h1["source", "Estimate"]
  simulation_small[i, "source_se"] <- reg_h1["source", "Std. Error"]
  simulation_small[i, "source_p"] <- reg_h1["source", "Pr(>|t|)"]
  reg_h2 <- summary(glm(belief ~ attitude*content, 
                        data = data_sim_assigned))$coefficients
  simulation_small[i, "content_att_coeff"] <- reg_h2["attitude:content", "Estimate"]
  simulation_small[i, "content_att_se"] <- reg_h2["attitude:content", "Std. Error"]
  simulation_small[i, "content_att_p"] <- reg_h2["attitude:content", "Pr(>|t|)"]
  reg_h3 <- summary(glm(belief ~ attitude*content*source, 
                        data = data_sim_assigned))$coefficients
  simulation_small[i, "content_source_att_coeff"] <- 
    reg_h3["attitude:content:source", "Estimate"]
  simulation_small[i, "content_source_att_se"] <- 
    reg_h3["attitude:content:source", "Std. Error"]
  simulation_small[i, "content_source_att_p"] <- 
    reg_h3["attitude:content:source", "Pr(>|t|)"]
}

# prop.table(table(simulation_small$source_p < 0.05))
# prop.table(table(simulation_small$content_att_p < 0.05))
# prop.table(table(simulation_small$content_source_att_p < 0.05))

## Moderate effect sizes

simulation_mod <- data.frame(index = 1:n_simulations,
                         source_coeff = NA, source_se = NA, source_p = NA,
                         content_att_coeff = NA, content_att_se = NA, content_att_p = NA,
                         content_source_att_coeff = NA, content_source_att_se = NA,
                         content_source_att_p = NA)

for (i in 1:n_simulations) {
  
  # Simulate random treatment assignment
  data_sim_assigned <- data_sim_mod %>%
    mutate(content = sample(0:1, n_sample, replace = TRUE),
           source = sample(0:1, n_sample, replace = TRUE)) %>%
    mutate(belief = case_when(content == 0 & source == 0 ~ belief_A_0_B_0,
                              content == 0 & source == 1 ~ belief_A_0_B_1,
                              content == 1 & source == 0 ~ belief_A_1_B_0,
                              content == 1 & source == 1 ~ belief_A_1_B_1))
  
  # Regressions for three different hypotheses
  reg_h1 <- summary(glm(belief ~ source, 
                        data = data_sim_assigned))$coefficients
  simulation_mod[i, "source_coeff"] <- reg_h1["source", "Estimate"]
  simulation_mod[i, "source_se"] <- reg_h1["source", "Std. Error"]
  simulation_mod[i, "source_p"] <- reg_h1["source", "Pr(>|t|)"]
  reg_h2 <- summary(glm(belief ~ attitude*content, 
                        data = data_sim_assigned))$coefficients
  simulation_mod[i, "content_att_coeff"] <- reg_h2["attitude:content", "Estimate"]
  simulation_mod[i, "content_att_se"] <- reg_h2["attitude:content", "Std. Error"]
  simulation_mod[i, "content_att_p"] <- reg_h2["attitude:content", "Pr(>|t|)"]
  reg_h3 <- summary(glm(belief ~ attitude*content*source, 
                        data = data_sim_assigned))$coefficients
  simulation_mod[i, "content_source_att_coeff"] <- 
    reg_h3["attitude:content:source", "Estimate"]
  simulation_mod[i, "content_source_att_se"] <- 
    reg_h3["attitude:content:source", "Std. Error"]
  simulation_mod[i, "content_source_att_p"] <- 
    reg_h3["attitude:content:source", "Pr(>|t|)"]
}

# prop.table(table(simulation_mod$source_p < 0.05))
# prop.table(table(simulation_mod$content_att_p < 0.05))
# prop.table(table(simulation_mod$content_source_att_p < 0.05))

```

\clearpage

# Main results

## Regression models

Table \@ref(tab:study1-fullmodels-table) reports the main regression results as referred to in the paper.

```{r study1-fullmodels}

# Content treatment: 0 is left-wing congruent content, 1 is right-wing congruent content
# Attitude: low is left-wing, high is right-wing

study1 <- list()

#### Topic 1 ####

study1$topic1_h1a <- glm(topic1_belief_stand ~ 
                    topic1_content*topic1_attitudes_average, data = data)

study1$topic1_h2a <- glm(topic1_belief_stand ~ 
                  topic1_source, data = data)

study1$topic1_h3a <- glm(topic1_belief_stand ~ 
                  topic1_content*topic1_attitudes_average*topic1_source, data = data)

#### Topic 2 ####

study1$topic2_h1a <- glm(topic2_belief_stand ~ 
                    topic2_content*topic2_attitudes_average, data = data)

study1$topic2_h2a <- glm(topic2_belief_stand ~ 
                  topic2_source, data = data)

study1$topic2_h3a <- glm(topic2_belief_stand ~ 
                  topic2_content*topic2_attitudes_average*topic2_source, data = data)

#### Topic 3 ####

study1$topic3_h1a <- glm(topic3_belief_stand ~ 
                  topic3_content*topic3_attitudes_average, data = data)

study1$topic3_h2a <- glm(topic3_belief_stand ~ 
                  topic3_source, data = data)

study1$topic3_h3a <- glm(topic3_belief_stand ~ 
                  topic3_content*topic3_attitudes_average*topic3_source, data = data)

#### Topic 4 ####

study1$topic4_h1a <- glm(topic4_belief_stand ~ 
                  topic4_content*topic4_attitudes_average, data = data)

study1$topic4_h2a <- glm(topic4_belief_stand ~ 
                  topic4_source, data = data)

study1$topic4_h3a <- glm(topic4_belief_stand ~ 
                  topic4_content*topic4_attitudes_average*topic4_source, data = data)

#### Rename coefficients for table and make cells bold ###

models_h1a <- paste0("topic", 1:4, "_h1a")
for(i in models_h1a) {
    names(study1[[i]]$coefficients) <- c("Constant",
                                             "Report (0 = left-wing)",
                                             "Attitude",
                                             "Report * Attitude")
}

models_h2a <- paste0("topic", 1:4, "_h2a")
for(i in models_h2a) {
  names(study1[[i]]$coefficients) <- c("Constant",
                                       "Source (0 = fake)")
}

models_h3a <- paste0("topic", 1:4, "_h3a")
for(i in models_h3a) {
  names(study1[[i]]$coefficients) <- c("Constant",
                                       "Report (0 = left-wing)",
                                       "Attitude",
                                       "Source (0 = fake)",
                                       "Report * Attitude",
                                       "Report * Source",
                                       "Attitude * Source",
                                       "Report * Attitude * Source")
}

```

```{r study1-fullmodels-table, results = "asis", paged.print = FALSE}

#### Table for all topics

stargazer(study1,
          type = "latex",
          table.placement = "!h",
          omit.stat = c("LL","ser","f","adj.rsq"),
          label = "tab:study1-fullmodels-table", 
          single.row = FALSE,
          no.space = FALSE,
          digits = 2,
          align = TRUE,
          font.size = "scriptsize",
          column.sep.width = "-14pt",
          star.cutoffs = c(0.05, 0.01, 0.001),
          covariate.labels = c("Constant",
                               "Report (0 = left-wing)",
                               "Attitude",
                               "Report * Attitude",
                               "Source (0 = fake)",
                               "Report * Source",
                               "Attitude * Source",
                               "Report * Attitude * Source",
                               "Constant"),
          order = c(1, 2, 3, 4, 8, 5, 6, 7),
          model.names = FALSE, 
          model.numbers = FALSE,
          title = "Study 1 effects on believing news reports",
          dep.var.caption = "Belief",
          column.labels = c("H1a", "H2a", "H3a",
                            "H1a", "H2a", "H3a",
                            "H1a", "H2a", "H3a",
                            "H1a", "H2a", "H3a"),
          dep.var.labels = c("Welfare State", "Domestic Security",
                             "Migration", "European integration"),
          header = FALSE)

```

## Marginal effects

Figure \@ref(fig:figure-h1a-margins) shows predicted content treatment effects.

```{r study1-h1a-margins}

# Topic 1

## Predict margins

topic1_h1_predict <- marg(study1$topic1_h1a, 
                       var_interest = "topic1_content", 
                       at = list("topic1_attitudes_average" = 
                                   c(-5:5)),
                                 type = "effects")

### Data frame for graph

topic1_h1_delta <- data.frame(at = NA, delta = NA, se = NA)

for (i in 1:length(topic1_h1_predict)) {
  topic1_h1_delta[i, "at"] <- names(topic1_h1_predict[i])
  topic1_h1_delta[i, "delta"] <- topic1_h1_predict[[i]][["Margin"]][2]
  topic1_h1_delta[i, "se"] <- topic1_h1_predict[[i]][["Standard.Error"]][2]
}

topic1_h1_delta %<>%
  mutate(at = gsub("topic1_attitudes_average = ", "", at)) %>%
  mutate(at = as.numeric(at)) %>%
  mutate(conf_low = delta - se) %>%
  mutate(conf_high = delta + se)

# Topic 2

## Predict margins

topic2_h1_predict <- marg(study1$topic2_h1a, 
                       var_interest = "topic2_content", 
                       at = list("topic2_attitudes_average" = 
                                   c(-5:5)), 
                       type = "effects")

### Data frame for graph

topic2_h1_delta <- data.frame(at = NA, delta = NA, se = NA)

for (i in 1:length(topic2_h1_predict)) {
  topic2_h1_delta[i, "at"] <- names(topic2_h1_predict[i])
  topic2_h1_delta[i, "delta"] <- topic2_h1_predict[[i]][["Margin"]][2]
  topic2_h1_delta[i, "se"] <- topic2_h1_predict[[i]][["Standard.Error"]][2]
}

topic2_h1_delta %<>%
  mutate(at = gsub("topic2_attitudes_average = ", "", at)) %>%
  mutate(at = as.numeric(at)) %>%
  mutate(conf_low = delta - se) %>%
  mutate(conf_high = delta + se)

# Topic 3

## Predict margins

topic3_h1_predict <- marg(study1$topic3_h1a, 
                       var_interest = "topic3_content", 
                       at = list("topic3_attitudes_average" = 
                                   c(-5:5)), 
                       type = "effects")

### Data frame for graph

topic3_h1_delta <- data.frame(at = NA, delta = NA, se = NA)
for (i in 1:length(topic3_h1_predict)) {
  topic3_h1_delta[i, "at"] <- names(topic3_h1_predict[i])
  topic3_h1_delta[i, "delta"] <- topic3_h1_predict[[i]][["Margin"]][2]
  topic3_h1_delta[i, "se"] <- topic3_h1_predict[[i]][["Standard.Error"]][2]
}

topic3_h1_delta %<>%
  mutate(at = gsub("topic3_attitudes_average = ", "", at)) %>%
  mutate(at = as.numeric(at)) %>%
  mutate(conf_low = delta - se) %>%
  mutate(conf_high = delta + se)

# Topic 4

## Predict margins

topic4_h1_predict <- marg(study1$topic4_h1a, 
                       var_interest = "topic4_content", 
                       at = list("topic4_attitudes_average" = 
                                   c(-5:5)), 
                       type = "effects")

### Data frame for graph

topic4_h1_delta <- data.frame(at = NA, delta = NA, se = NA)

for (i in 1:length(topic4_h1_predict)) {
  topic4_h1_delta[i, "at"] <- names(topic4_h1_predict[i])
  topic4_h1_delta[i, "delta"] <- topic4_h1_predict[[i]][["Margin"]][2]
  topic4_h1_delta[i, "se"] <- topic4_h1_predict[[i]][["Standard.Error"]][2]
}

topic4_h1_delta %<>%
  mutate(at = gsub("topic4_attitudes_average = ", "", at)) %>%
  mutate(at = as.numeric(at)) %>%
  mutate(conf_low = delta - se) %>%
  mutate(conf_high = delta + se)


```

```{r study1-h1a-margins-plot, results = "hide", fig.cap = "Marginal congruence effects on belief\\label{fig:figure-h1a-margins}", fig.height = 2.2, out.extra = '', fig.pos= "H"}

h1a_marginsplot <- function(margins_data, x_lab, y_lab = NULL, title, rug_data) {
  ggplot(margins_data, aes(x = at, y = delta)) +
    geom_point() + 
    geom_errorbar(aes(ymin = conf_low, ymax = conf_high), 
                  width=.05) + 
    geom_line() +
    geom_hline(yintercept = 0, linetype = "dashed", color = "gray") + 
    labs(y = y_lab, x = x_lab, title = title) +
    scale_x_continuous(breaks = c(-5, 0, 5)) +
    scale_y_continuous(breaks = c(-1.5, 0, 1.5)) +
    theme_light() + 
    theme(legend.key = element_blank(),
          axis.title.x = element_text(size = 8),
          plot.title = element_text(size = 9)) +
    geom_rug(inherit.aes = FALSE, 
             aes(x = attitude, y = y),
             data = rug_data, 
             sides="b", alpha = 0.1, size = 1.2, position = "jitter")
}

#### Topic 1

## Attitude dimension as new data frame

topic1_attitude_df = data.frame(attitude = data$topic1_attitudes_average, y = 0)

## Plot

topic1_h1a_marginsplot <- h1a_marginsplot(topic1_h1_delta, 
                                          x_lab = "Welfare attitude index", 
                                          y_lab = "Predicted difference",
                                          title = "(A) Welfare state",
                                          rug_data = topic1_attitude_df)

#### Topic 2

## Attitude dimension as new data frame

topic2_attitude_df = data.frame(attitude = data$topic2_attitudes_average, y = 0)

## Plot

topic2_h1a_marginsplot <- h1a_marginsplot(topic2_h1_delta, 
                                          x_lab = "Security attitude index", 
                                          title = "(B) Domestic security", 
                                          rug_data = topic2_attitude_df)

#### Topic 3

## Attitude dimension as new data frame

topic3_attitude_df = data.frame(attitude = data$topic3_attitudes_average, y = 0)

## Plot

topic3_h1a_marginsplot <- h1a_marginsplot(topic3_h1_delta, 
                                          x_lab = "Immigration attitude index", 
                                          title = "(C) Immigration",
                                          rug_data = topic3_attitude_df)

#### Topic 4

## Attitude dimension as new data frame

topic4_attitude_df = data.frame(attitude = data$topic4_attitudes_average, y = 0)

## Plot

topic4_h1a_marginsplot <- h1a_marginsplot(topic4_h1_delta, 
                                          x_lab = "Europe attitude index", 
                                          title = "European integration",
                                          rug_data = topic4_attitude_df)

#### Combine plots

ggarrange(topic1_h1a_marginsplot, 
         topic2_h1a_marginsplot,
         topic3_h1a_marginsplot, 
         topic4_h1a_marginsplot,
         # font.label = list(size = 12),
         ncol = 4, nrow = 1, 
         common.legend = TRUE,
         legend = "bottom")

```

# Robustness checks

When re-running analyses for the welfare state topic with individual attitude items instead of the average index, the congruence interaction remains significant for all but one item (Table \@ref(tab:study1-robust1-welfare)). Using individual attitude items for the domestic security topic does not change the main results (Table \@ref(tab:study1-robust2-security)). Table \@ref(tab:study1-robust3-cheaters) and Table \@ref(tab:study1-robust4-fbusers) show that results for all topics remain unchanged when cheaters are excluded from the sample, and when those not using Facebook are excluded. Since topic order was not randomized, Table \@ref(tab:study1-robust5-order) tests whether being previously exposed to one type of content treatment systematically affects later belief, which is not the case.

```{r study1-robust1-welfare, results = "asis", paged.print = FALSE}

study1_robust1 <- list()

#### Topic 1 ####

### Alternative model: Attitude 1

study1_robust1$topic1_h1a_att1 <- glm(topic1_belief_stand ~ 
                    topic1_content*topic1_attitude1, data = data)

study1_robust1$topic1_h3a_att1 <- glm(topic1_belief_stand ~ 
                  topic1_content*topic1_attitude1*topic1_source, data = data)

### Alternative model: Attitude 2

study1_robust1$topic1_h1a_att2 <- glm(topic1_belief_stand ~ 
                                   topic1_content*topic1_attitude2, 
                                 data = data)

study1_robust1$topic1_h3a_att2 <- glm(topic1_belief_stand ~ 
                                   topic1_content*topic1_attitude2*topic1_source, 
                                 data = data)

### Alternative model: Attitude 3

study1_robust1$topic1_h1a_att3 <- glm(topic1_belief_stand ~ 
                    topic1_content*topic1_attitude3, data = data)

study1_robust1$topic1_h3a_att3 <- glm(topic1_belief_stand ~ 
                  topic1_content*topic1_attitude3*topic1_source, data = data)

### Alternative model: Attitude 4

study1_robust1$topic1_h1a_att4 <- glm(topic1_belief_stand ~ 
                    topic1_content*topic1_attitude4, data = data)

study1_robust1$topic1_h3a_att4 <- glm(topic1_belief_stand ~ 
                  topic1_content*topic1_attitude4*topic1_source, data = data)

### Rename coefficients for table

models_h1a_robust1 <- paste0("topic1_h1a_att", 1:4)
for(i in models_h1a_robust1) {
  names(study1_robust1[[i]]$coefficients) <- c("Constant",
                                               "Report (0 = left-wing)",
                                               "Attitude",
                                               "Report * Attitude")
}

models_h3a_robust1 <- paste0("topic1_h3a_att", 1:4)
for(i in models_h3a_robust1) {
  names(study1_robust1[[i]]$coefficients) <- c("Constant",
                                       "Report (0 = left-wing)",
                                       "Attitude",
                                       "Source (0 = fake)",
                                       "Report * Attitude",
                                       "Report * Source",
                                       "Attitude * Source",
                                       "Report * Attitude * Source")
}

### Table

stargazer(study1_robust1$topic1_h1a_att2, study1_robust1$topic1_h3a_att2,
          study1_robust1$topic1_h1a_att1, study1_robust1$topic1_h3a_att1,
          study1_robust1$topic1_h1a_att3, study1_robust1$topic1_h3a_att3,
          study1_robust1$topic1_h1a_att4, study1_robust1$topic1_h3a_att4,
          type = "latex",
          table.placement = "!ht",
          omit.stat = c("LL","ser","f","adj.rsq"),
          single.row = FALSE,
          no.space = FALSE,
          digits = 2,
          align = TRUE,
          font.size = "scriptsize",
          column.sep.width = "-10pt",
          star.cutoffs = c(0.05, 0.01, 0.005),
          covariate.labels = c("Constant",
                               "Report (0 = left-wing)",
                               "Attitude",
                               "Report * Attitude",
                               "Source (0 = fake)",
                               "Report * Source",
                               "Attitude * Source",
                               "Report * Attitude * Source"),
          order = c(1, 2, 3, 5, 4, 6, 7, 8),
          model.names = FALSE, 
          model.numbers = FALSE,
          title = "Study 1 welfare state report with individual attitude items",
          label = "tab:study1-robust1-welfare", 
          dep.var.caption = "Belief",
          column.labels   = c("Attitude 1", "Attitude 2",
                             "Attitude 3", "Attitude 4"),
          column.separate = c(2, 2, 2, 2),
          dep.var.labels = c("Attitude item used"),
          header = FALSE)

```

```{r study1-robust2-security, results = "asis", paged.print = FALSE}

study1_robust2 <- list()

#### Topic 1 ####

### Alternative model: Attitude 1

study1_robust2$topic2_h1a_att1 <- glm(topic2_belief_stand ~ 
                    topic2_content*topic2_attitude1, data = data)

study1_robust2$topic2_h3a_att1 <- glm(topic2_belief_stand ~ 
                  topic2_content*topic2_attitude1*topic2_source, data = data)

### Alternative model: Attitude 2

study1_robust2$topic2_h1a_att2 <- glm(topic2_belief_stand ~ 
                                   topic2_content*topic2_attitude2, 
                                 data = data)

study1_robust2$topic2_h3a_att2 <- glm(topic2_belief_stand ~ 
                                   topic2_content*topic2_attitude2*topic2_source, 
                                 data = data)

### Alternative model: Attitude 3

study1_robust2$topic2_h1a_att3 <- glm(topic2_belief_stand ~ 
                    topic2_content*topic2_attitude3, data = data)

study1_robust2$topic2_h3a_att3 <- glm(topic2_belief_stand ~ 
                  topic2_content*topic2_attitude3*topic2_source, data = data)

### Alternative model: Attitude 4

study1_robust2$topic2_h1a_att4 <- glm(topic2_belief_stand ~ 
                    topic2_content*topic2_attitude4, data = data)

study1_robust2$topic2_h3a_att4 <- glm(topic2_belief_stand ~ 
                  topic2_content*topic2_attitude4*topic2_source, data = data)

### Rename coefficients for table

models_h1a_robust2 <- paste0("topic2_h1a_att", 1:4)
for(i in models_h1a_robust2) {
  names(study1_robust2[[i]]$coefficients) <- c("Constant",
                                               "Report (0 = left-wing)",
                                               "Attitude",
                                               "Report * Attitude")
}

models_h3a_robust2 <- paste0("topic2_h3a_att", 1:4)
for(i in models_h3a_robust2) {
  names(study1_robust2[[i]]$coefficients) <- c("Constant",
                                       "Report (0 = left-wing)",
                                       "Attitude",
                                       "Source (0 = fake)",
                                       "Report * Attitude",
                                       "Report * Source",
                                       "Attitude * Source",
                                       "Report * Attitude * Source")
}

### Table

stargazer(study1_robust2$topic2_h1a_att2, study1_robust2$topic2_h3a_att2,
          study1_robust2$topic2_h1a_att1, study1_robust2$topic2_h3a_att1,
          study1_robust2$topic2_h1a_att3, study1_robust2$topic2_h3a_att3,
          study1_robust2$topic2_h1a_att4, study1_robust2$topic2_h3a_att4,
          type = "latex",
          table.placement = "!ht",
          omit.stat = c("LL","ser","f","adj.rsq"),
          single.row = FALSE,
          no.space = FALSE,
          digits = 2,
          align = TRUE,
          font.size = "scriptsize",
          column.sep.width = "-10pt",
          star.cutoffs = c(0.05, 0.01, 0.005),
          covariate.labels = c("Constant",
                               "Report (0 = left-wing)",
                               "Attitude",
                               "Report * Attitude",
                               "Source (0 = fake)",
                               "Report * Source",
                               "Attitude * Source",
                               "Report * Attitude * Source"),
          order = c(1, 2, 3, 5, 4, 6, 7, 8),
          model.names = FALSE, 
          model.numbers = FALSE,
          title = "Study 1 domestic security report with individual attitude items",
          label = "tab:study1-robust2-security", 
          dep.var.caption = "Belief",
          column.labels   = c("Attitude 1", "Attitude 2",
                             "Attitude 3", "Attitude 4"),
          column.separate = c(2, 2, 2, 2),
          dep.var.labels = c("Attitude item used"),
          header = FALSE)

```

```{r study1-robust3-cheaters, results = "asis", paged.print = FALSE}

#### Exclude cheating suspects

data_nocheaters <- data %>% 
  filter(!(truestory_belief == 10 & truestory_belief_submit > 15))

# Content treatment: 0 is left-wing congruent content, 1 is right-wing congruent content
# Attitude: low is left-wing, high is right-wing

study1_robust3 <- list()

#### Topic 1 ####

### Main models: Attitude 2

study1_robust3$topic1_h1a <- glm(topic1_belief_stand ~ 
                                      topic1_content*topic1_attitudes_average, 
                                    data = data_nocheaters)

study1_robust3$topic1_h2a <- glm(topic1_belief_stand ~ 
                                      topic1_source, data = data_nocheaters)

study1_robust3$topic1_h3a <- glm(topic1_belief_stand ~ 
                                  topic1_content*topic1_attitudes_average*topic1_source, 
                                    data = data_nocheaters)

#### Topic 2 ####

study1_robust3$topic2_h1a <- glm(topic2_belief_stand ~ 
                                      topic2_content*topic2_attitudes_average, 
                                    data = data_nocheaters)

study1_robust3$topic2_h2a <- glm(topic2_belief_stand ~ 
                                      topic2_source, 
                                    data = data_nocheaters)

study1_robust3$topic2_h3a <- glm(topic2_belief_stand ~ 
                                  topic2_content*topic2_attitudes_average*topic2_source,
                                 data = data_nocheaters)

#### Topic 3 ####

study1_robust3$topic3_h1a <- glm(topic3_belief_stand ~ 
                                      topic3_content*topic3_attitudes_average, 
                                    data = data_nocheaters)

study1_robust3$topic3_h2a <- glm(topic3_belief_stand ~ 
                                      topic3_source, 
                                    data = data_nocheaters)

study1_robust3$topic3_h3a <- glm(topic3_belief_stand ~ 
                                   topic3_content*topic3_attitudes_average*topic3_source, 
                                 data = data_nocheaters)

#### Topic 4 ####

study1_robust3$topic4_h1a <- glm(topic4_belief_stand ~ 
                                      topic4_content*topic4_attitudes_average, 
                                    data = data_nocheaters)

study1_robust3$topic4_h2a <- glm(topic4_belief_stand ~ 
                                      topic4_source, 
                                    data = data_nocheaters)

study1_robust3$topic4_h3a <- glm(topic4_belief_stand ~
                                   topic4_content*topic4_attitudes_average*topic4_source, 
                                    data = data_nocheaters)

#### Rename coefficients for table ###

models_h1a <- paste0("topic", 1:4, "_h1a")
for(i in models_h1a) {
  names(study1_robust3[[i]]$coefficients) <- c("Constant",
                                                  "Report (0 = left-wing)",
                                                         "Attitude",
                                                         "Report * Attitude")
}

models_h2a <- paste0("topic", 1:4, "_h2a")
for(i in models_h2a) {
  names(study1_robust3[[i]]$coefficients) <- c("Constant",
                                                         "Source (0 = fake)")
}

models_h3a <- paste0("topic", 1:4, "_h3a")
for(i in models_h3a) {
  names(study1_robust3[[i]]$coefficients) <- c("Constant",
                                                         "Report (0 = left-wing)",
                                                         "Attitude",
                                                         "Source (0 = fake)",
                                                         "Report * Attitude",
                                                         "Report * Source",
                                                         "Attitude * Source",
                                                         "Report * Attitude * Source")
}

#### Table for all topics ####
stargazer(study1_robust3,
          type = "latex",
          table.placement = "!ht",
          omit.stat = c("LL","ser","f","adj.rsq"),
          label = "tab:study1-robust3-cheaters", 
          single.row = FALSE,
          no.space = FALSE,
          digits = 2,
          align = TRUE,
          font.size = "scriptsize",
          column.sep.width = "-14pt",
          star.cutoffs = c(0.05, 0.01, 0.005),
          covariate.labels = c("Constant",
                               "Report (0 = left-wing)",
                               "Attitude",
                               "Report * Attitude",
                               "Source (0 = fake)",
                               "Report * Source",
                               "Attitude * Source",
                               "Report * Attitude * Source",
                               "Constant"),
          order = c(1, 2, 3, 4, 8, 5, 6, 7),
          model.names = FALSE, 
          model.numbers = FALSE,
          title = "Study 1 without cheating suspects",
          dep.var.caption = "Belief",
          column.labels = c("H1a", "H2a", "H3a",
                            "H1a", "H2a", "H3a",
                            "H1a", "H2a", "H3a",
                            "H1a", "H2a", "H3a"),
          dep.var.labels = c("Welfare State", "Domestic Security",
                             "Migration", "European integration"),
          header = FALSE)

```

```{r study1-robust4-fbusers, results = "asis", paged.print = FALSE}

#### Exclude cheating suspects ####

data_fbusers <- data %>% 
  filter(fb_account == "Ja")

# Content treatment: 0 is left-wing congruent content, 1 is right-wing congruent content
# Attitude: low is left-wing, high is right-wing

study1_robust4 <- list()

#### Topic 1 ####

### Main models: Attitude 2


study1_robust4$topic1_h1a <- glm(topic1_belief_stand ~ 
                                      topic1_content*topic1_attitudes_average, 
                                    data = data_fbusers)

study1_robust4$topic1_h2a <- glm(topic1_belief_stand ~ 
                                      topic1_source, data = data_fbusers)

study1_robust4$topic1_h3a <- glm(topic1_belief_stand ~ 
                                   topic1_content*topic1_attitudes_average*topic1_source, 
                                    data = data_fbusers)

#### Topic 2 ####

study1_robust4$topic2_h1a <- glm(topic2_belief_stand ~ 
                                      topic2_content*topic2_attitudes_average, 
                                    data = data_fbusers)

study1_robust4$topic2_h2a <- glm(topic2_belief_stand ~ 
                                      topic2_source, 
                                    data = data_fbusers)

study1_robust4$topic2_h3a <- glm(topic2_belief_stand ~
                                   topic2_content*topic2_attitudes_average*topic2_source, 
                                    data = data_fbusers)

#### Topic 3 ####

study1_robust4$topic3_h1a <- glm(topic3_belief_stand ~ 
                                      topic3_content*topic3_attitudes_average, 
                                    data = data_fbusers)

study1_robust4$topic3_h2a <- glm(topic3_belief_stand ~ 
                                      topic3_source, 
                                    data = data_fbusers)

study1_robust4$topic3_h3a <- glm(topic3_belief_stand ~ 
                                   topic3_content*topic3_attitudes_average*topic3_source, 
                                    data = data_fbusers)

#### Topic 4 ####

study1_robust4$topic4_h1a <- glm(topic4_belief_stand ~ 
                                      topic4_content*topic4_attitudes_average, 
                                    data = data_fbusers)

study1_robust4$topic4_h2a <- glm(topic4_belief_stand ~ 
                                      topic4_source, 
                                    data = data_fbusers)

study1_robust4$topic4_h3a <- glm(topic4_belief_stand ~ 
                                   topic4_content*topic4_attitudes_average*topic4_source, 
                                    data = data_fbusers)

#### Rename coefficients for table ###

models_h1a <- paste0("topic", 1:4, "_h1a")
for(i in models_h1a) {
  names(study1_robust4[[i]]$coefficients) <- c("Constant",
                                                  "Report (0 = left-wing)",
                                                         "Attitude",
                                                         "Report * Attitude")
}

models_h2a <- paste0("topic", 1:4, "_h2a")
for(i in models_h2a) {
  names(study1_robust4[[i]]$coefficients) <- c("Constant",
                                                         "Source (0 = fake)")
}

models_h3a <- paste0("topic", 1:4, "_h3a")
for(i in models_h3a) {
  names(study1_robust4[[i]]$coefficients) <- c("Constant",
                                                         "Report (0 = left-wing)",
                                                         "Attitude",
                                                         "Source (0 = real)",
                                                         "Report * Attitude",
                                                         "Report * Source",
                                                         "Attitude * Source",
                                                         "Report * Attitude * Source")
}

#### Table for all topics ####

stargazer(study1_robust4,
          type = "latex",
          table.placement = "!ht",
          omit.stat = c("LL","ser","f","adj.rsq"),
          label = "tab:study1-robust4-fbusers", 
          single.row = FALSE,
          no.space = FALSE,
          digits = 2,
          align = TRUE,
          font.size = "scriptsize",
          column.sep.width = "-14pt",
          star.cutoffs = c(0.05, 0.01, 0.005),
          covariate.labels = c("Constant",
                               "Report (0 = left-wing)",
                               "Attitude",
                               "Report * Attitude",
                               "Source (0 = fake)",
                               "Report * Source",
                               "Attitude * Source",
                               "Report * Attitude * Source",
                               "Constant"),
          order = c(1, 2, 3, 4, 8, 5, 6, 7),
          model.names = FALSE, 
          model.numbers = FALSE,
          title = "Study 1 Facebook users only",
          dep.var.caption = "Belief",
          column.labels = c("H1a", "H2a", "H3a",
                            "H1a", "H2a", "H3a",
                            "H1a", "H2a", "H3a",
                            "H1a", "H2a", "H3a"),
          dep.var.labels = c("Welfare State", "Domestic Security",
                             "Migration", "European integration"),
          header = FALSE)

```

```{r study1-robust5-order, results = "asis", paged.print = FALSE}

study1_robust5 <- list()

study1_robust5$topic2 <- glm(topic2_belief_stand ~ 
                               topic1_content, data = data)
study1_robust5$topic3 <- glm(topic3_belief_stand ~ 
                               topic1_content*topic2_content, data = data)
study1_robust5$topic4 <- glm(topic4_belief_stand ~ 
                               topic1_content*topic2_content*topic3_content, data = data)

# Table for all topics

stargazer(study1_robust5,
          type = "latex",
          table.placement = "!ht",
          omit.stat = c("LL","ser","f","adj.rsq"),
          label = "tab:study1-robust5-order", 
          single.row = FALSE,
          no.space = FALSE,
          digits = 2,
          align = TRUE,
          font.size = "scriptsize",
          column.sep.width = "-10pt",
          star.cutoffs = c(0.05, 0.01, 0.001),
          covariate.labels = c("Welfare state content treatment",
                               "Domestic security content treatment",
                               "Migration content treatment",
                               "Welfare state * Domestic security",
                               "Welfare state * Migration",
                               "Domestic security * Migration",
                               "Welfare state * Domestic security * Migration",
                               "Constant"),
          model.names = FALSE, 
          model.numbers = FALSE,
          title = "Study 1 effects of report order",
          dep.var.caption = "Belief",
          dep.var.labels = c("Domestic security", "Migration", 
                             "European integration"),
          header = FALSE)


```

\clearpage

# Heterogeneity

Figures \@ref(fig:congruence-topic1-het) to \@ref(fig:congruence-topic4-het) show heterogeneity of the congruence effect across the four topics. Figures \@ref(fig:source-topic1-het) to \@ref(fig:source-topic4-het) illustrate heterogeneity for the source effect. Each figure shows the covariates most "important" for that tree according to the causal forest algorithm [@WagerAthey2018; @Atheyetal2019]. 

```{r heterogeneity-setup}

set.seed(1404)

# Random forest specifications
number_of_trees <- 30000
tree_depth <- 4

# Pre-treatment variables

X_vars <- c(
  "sex", 
  "age", 
  "education_num",
  "federal_state_west",
  "trustsource_mainstream", 
  "leftright", 
  "political_interest", 
  "political_knowledge", 
  "importance_fb_num", 
  "media_frequency_num", 
  "turnout_intent_num"
  )

## Define continuous variables for plotting

continuous_vars <- c(
  "education_num",
  "trustsource_mainstream", 
  "political_interest", 
  "political_knowledge",
  "age", 
  "leftright", 
  "importance_fb_num", 
  "media_frequency_num"
)

# Functions

forest_data <- function(W, Y) {
  
  # Subset needed data
  data_het <- data %>% 
    select(all_of(X_vars), W, Y) %>% 
    na.omit()
  data_X <- data_het %>% select(-Y, -W)
  data_Y <- data_het[[Y]]
  data_W <- data_het[[W]]
  
  # Estimate pilot forest
  pilot_forest <- causal_forest(
    X = data_X,
    Y = data_Y,
    W = data_W,
    num.trees = number_of_trees
    )
  
  # Variable importance pilot forest
  variable_importance <- pilot_forest %>%
    variable_importance(max.depth = tree_depth) %>%
    as.data.frame() %>%
    mutate(variable = colnames(pilot_forest$X.orig)) %>%
    arrange(desc(V1))
  
  # Select variables with importance higher than average
  X_vars_selected <- variable_importance %>%
    filter(V1 >= median(V1)) %>%
    select(variable) %>%
    pull()
  
  # Subset data again
  data_het <- data %>% 
    select(all_of(X_vars_selected), W, Y) %>% 
    na.omit()
  
  return(data_het)
}

grow_forest <- function(data_het, W, Y) {
  
  # Split treatment, outcome, covariates
  data_X <- data_het %>% select(-Y, -W)
  data_Y <- data_het[[Y]]
  data_W <- data_het[[W]]
  
  # Estimate final forest
  forest <- causal_forest(
    X = data_X,
    Y = data_Y,
    W = data_W,
    num.trees = number_of_trees
    ) 
  
  return(forest)
}

forest_varimp <- function(forest) {
  
  # Recalculate and annotate importance
  variable_importance <- forest %>%
    variable_importance(max.depth = tree_depth) %>%
    as.data.frame() %>%
    mutate(variable = colnames(forest$X.orig)) %>%
    arrange(desc(V1)) %>%
    mutate(type = ifelse(
      variable %in% continuous_vars, 
      "continuous", "categorical"),
      label = case_when(
        variable == "sex" ~ "Gender",
        variable == "age" ~ "Age", 
        variable == "education_num" ~ "Education",
        variable == "federal_state_west" ~ "Residence",
        variable == "trustsource_mainstream" ~ "Media trust",
        variable == "leftright" ~ "Left-right orientation",
        variable == "political_interest" ~ "Political interest",
        variable == "political_knowledge" ~ "Political knowledge",
        variable == "importance_fb_num" ~ "Importance of FB",
        variable == "media_frequency_num" ~ "Frequency of media use",
        variable == "turnout_intent_num" ~ "Turnout intention"
        )
    )
  
  return(variable_importance)
  
}

forest_predict <- function(forest, data_het) {
  
  tau_hat <- predict(forest, estimate.variance = TRUE)
  data_het_predict <- bind_cols(data_het, tau_hat)
  return(data_het_predict)
  
}

plot_het_vars <- function(variable_importance, data_het) {
  
  plot_list <- list()
  
  for (i in 1:nrow(variable_importance)) {
  
    var <- variable_importance$variable[i]
    var_label <- variable_importance$label[i]
    plot_number <- LETTERS[seq(from = 1, to = nrow(variable_importance))][i]

    data_plot <- data_het %>% select(var, predictions)

    if (variable_importance$type[i] == "continuous") {
      plot <- ggplot(data_plot, aes_string(
        x = as.name(var),
        y = as.name("predictions")
      )) +
        geom_point(alpha = 3 / 10) +
        geom_smooth(method = "loess", span = 1, se = F, colour = "gray") +
        labs(title = paste0("(", plot_number, ") ", var_label)) +
        theme_light() +
        theme(
          axis.text.x = element_text(size = 6, angle = 0),
          axis.title.y = element_blank(),
          axis.title.x = element_blank(),
          plot.title = element_text(size = 8)
        )
    } else {
      data_plot[, var] <- factor(round(data_plot[, var]))
  
      labels <- data %>%
        select(gsub("_num", "", var)) %>%
        table() %>%
        rownames()
  
      plot <- ggplot(data_plot, aes_string(
        x = as.name(var),
        y = as.name("predictions")
      )) +
        geom_boxplot() +
        geom_smooth(method = "loess", se = FALSE, aes(group = 1), colour = "gray") +
        labs(title = paste0("(", plot_number, ") ", var_label)) +
        scale_x_discrete(labels = labels) +
        theme_light() +
        theme(
          axis.text.x = element_text(
            size = 6, angle = angle,
            hjust = 1, vjust = 1
          ),
          axis.title.y = element_blank(),
          axis.title.x = element_blank(),
          plot.title = element_text(size = 8)
        )
    }
  plot_list[[i]] <- plot
  }
return(plot_list)
}

```

```{r congruence-topic1-het, fig.cap="Congruence treatment heterogeneity (welfare state)", fig.height=3, fig.width = 5.5, out.extra = '', fig.pos= "!h", fig.align = "center"}

data_het_topic1_congruence <- forest_data(
  W = "topic1_congruence", 
  Y = "topic1_belief"
  )

forest_topic1_congruence <- grow_forest(
  data_het = data_het_topic1_congruence, 
  W = "topic1_congruence", 
  Y = "topic1_belief"
  )

varimp_topic1_congruence <- forest_varimp(
  forest = forest_topic1_congruence
  )

data_het_topic1_congruence <- forest_predict(
  forest = forest_topic1_congruence,
  data_het = data_het_topic1_congruence
)

plots_het_topic1_congruence <- plot_het_vars(
  variable_importance = varimp_topic1_congruence, 
  data_het = data_het_topic1_congruence
)

ggarrange(
  plotlist = plots_het_topic1_congruence,
  common.legend = TRUE,
  legend = "bottom", ncol = 3, nrow = 2)

```

```{r congruence-topic2-het, fig.cap="Congruence treatment heterogeneity (domestic security)", fig.height=3, fig.width = 5.5, out.extra = '', fig.pos= "!h", fig.align = "center"}

data_het_topic2_congruence <- forest_data(
  W = "topic2_congruence", 
  Y = "topic2_belief"
  )

forest_topic2_congruence <- grow_forest(
  data_het = data_het_topic2_congruence, 
  W = "topic2_congruence", 
  Y = "topic2_belief"
  )

varimp_topic2_congruence <- forest_varimp(
  forest = forest_topic2_congruence
  )

data_het_topic2_congruence <- forest_predict(
  forest = forest_topic2_congruence,
  data_het = data_het_topic2_congruence
)

plots_het_topic2_congruence <- plot_het_vars(
  variable_importance = varimp_topic2_congruence, 
  data_het = data_het_topic2_congruence
)

ggarrange(
  plotlist = plots_het_topic2_congruence,
  common.legend = TRUE,
  legend = "bottom", ncol = 3, nrow = 2)

```

```{r congruence-topic3-het, fig.cap="Congruence treatment heterogeneity (immigration)", fig.height=3, fig.width = 5.5, out.extra = '', fig.pos= "!h", fig.align = "center"}

data_het_topic3_congruence <- forest_data(
  W = "topic3_congruence", 
  Y = "topic3_belief"
  )

forest_topic3_congruence <- grow_forest(
  data_het = data_het_topic3_congruence, 
  W = "topic3_congruence", 
  Y = "topic3_belief"
  )

varimp_topic3_congruence <- forest_varimp(
  forest = forest_topic3_congruence
  )

data_het_topic3_congruence <- forest_predict(
  forest = forest_topic3_congruence,
  data_het = data_het_topic3_congruence
)

plots_het_topic3_congruence <- plot_het_vars(
  variable_importance = varimp_topic3_congruence, 
  data_het = data_het_topic3_congruence
)

ggarrange(plotlist = plots_het_topic3_congruence,
  common.legend = TRUE,
  legend = "bottom", ncol = 3, nrow = 2) 

```

```{r congruence-topic4-het, fig.cap="Congruence treatment heterogeneity (European integration)", fig.height=3, fig.width = 5.5, out.extra = '', fig.pos= "!h", fig.align = "center"}

data_het_topic4_congruence <- forest_data(
  W = "topic4_congruence", 
  Y = "topic4_belief"
  )

forest_topic4_congruence <- grow_forest(
  data_het = data_het_topic4_congruence, 
  W = "topic4_congruence", 
  Y = "topic4_belief"
  )

varimp_topic4_congruence <- forest_varimp(
  forest = forest_topic4_congruence
  )

data_het_topic4_congruence <- forest_predict(
  forest = forest_topic4_congruence,
  data_het = data_het_topic4_congruence
)

plots_het_topic4_congruence <- plot_het_vars(
  variable_importance = varimp_topic4_congruence, 
  data_het = data_het_topic4_congruence
)

ggarrange(plotlist = plots_het_topic4_congruence,
  common.legend = TRUE,
  legend = "bottom", ncol = 3, nrow = 2) 

```

```{r source-topic1-het, fig.cap="Source treatment heterogeneity (welfare state)", fig.height=3, fig.width = 5, out.extra = '', fig.pos= "!h", fig.align = "center"}

data_het_topic1_source <- forest_data(
  W = "topic1_source", 
  Y = "topic1_belief"
  )

forest_topic1_source <- grow_forest(
  data_het = data_het_topic1_source, 
  W = "topic1_source", 
  Y = "topic1_belief"
  )

varimp_topic1_source <- forest_varimp(
  forest = forest_topic1_source
  )

data_het_topic1_source <- forest_predict(
  forest = forest_topic1_source,
  data_het = data_het_topic1_source
)

plots_het_topic1_source <- plot_het_vars(
  variable_importance = varimp_topic1_source, 
  data_het = data_het_topic1_source
)

ggarrange(
  plotlist = plots_het_topic1_source,
  common.legend = TRUE,
  legend = "bottom", ncol = 3, nrow = 2)

```

```{r source-topic2-het, fig.cap="Source treatment heterogeneity (domestic security)", fig.height=3, fig.width = 5, out.extra = '', fig.pos= "!h", fig.align = "center"}

data_het_topic2_source <- forest_data(
  W = "topic2_source", 
  Y = "topic2_belief"
  )

forest_topic2_source <- grow_forest(
  data_het = data_het_topic2_source, 
  W = "topic2_source", 
  Y = "topic2_belief"
  )

varimp_topic2_source <- forest_varimp(
  forest = forest_topic2_source
  )

data_het_topic2_source <- forest_predict(
  forest = forest_topic2_source,
  data_het = data_het_topic2_source
)

plots_het_topic2_source <- plot_het_vars(
  variable_importance = varimp_topic2_source, 
  data_het = data_het_topic2_source
)

ggarrange(
  plotlist = plots_het_topic2_source,
  common.legend = TRUE,
  legend = "bottom", ncol = 3, nrow = 2) 

```

```{r source-topic3-het, fig.cap="Source treatment heterogeneity (immigration)", fig.height=3, fig.width = 5, out.extra = '', fig.pos= "!h", fig.align = "center"}

data_het_topic3_source <- forest_data(
  W = "topic3_source", 
  Y = "topic3_belief"
  )

forest_topic3_source <- grow_forest(
  data_het = data_het_topic3_source, 
  W = "topic3_source", 
  Y = "topic3_belief"
  )

varimp_topic3_source <- forest_varimp(
  forest = forest_topic3_source
  )

data_het_topic3_source <- forest_predict(
  forest = forest_topic3_source,
  data_het = data_het_topic3_source
)

plots_het_topic3_source <- plot_het_vars(
  variable_importance = varimp_topic3_source, 
  data_het = data_het_topic3_source
)

ggarrange(
  plotlist = plots_het_topic3_source,
  common.legend = TRUE,
  legend = "bottom", ncol = 3, nrow = 2) 
```

```{r source-topic4-het, fig.cap="Source treatment heterogeneity (European integration)", fig.height=3, fig.width = 5, out.extra = '', fig.pos= "!h", fig.align = "center"}

data_het_topic4_source <- forest_data(
  W = "topic4_source", 
  Y = "topic4_belief"
  )

forest_topic4_source <- grow_forest(
  data_het = data_het_topic4_source, 
  W = "topic4_source", 
  Y = "topic4_belief"
  )

varimp_topic4_source <- forest_varimp(
  forest = forest_topic4_source
  )

data_het_topic4_source <- forest_predict(
  forest = forest_topic4_source,
  data_het = data_het_topic4_source
)

plots_het_topic4_source <- plot_het_vars(
  variable_importance = varimp_topic4_source, 
  data_het = data_het_topic4_source
)

ggarrange(
  plotlist = plots_het_topic4_source,
  common.legend = TRUE,
  legend = "bottom", ncol = 3, nrow = 2)

```
\clearpage

# References
